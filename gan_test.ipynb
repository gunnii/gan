{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Data and variances]\n",
      "0: D: 0.7591767311096191/0.6492283940315247 G: 0.7404654622077942 (Real: [3.7744895476102829, 1.2127879487501048], Fake: [-0.080349415764212603, 0.0040373059949561415]) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:767: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200: D: 0.000754163833335042/0.6369110345840454 G: 0.7691926956176758 (Real: [4.0486575376987455, 1.2539147953408929], Fake: [-0.39132367789745331, 0.0049814184192758003]) \n",
      "400: D: 5.614915062324144e-05/0.5187681913375854 G: 0.9356982707977295 (Real: [3.8863593947887423, 1.3437744502831639], Fake: [-0.38369377285242079, 0.0085378762138881292]) \n",
      "600: D: 6.675741587969242e-06/0.35793426632881165 G: 1.2138944864273071 (Real: [3.9529964721202848, 1.3199351706128957], Fake: [-0.38372327983379362, 0.056591286684082628]) \n",
      "800: D: 6.437321189878276e-06/0.19419550895690918 G: 1.9797745943069458 (Real: [3.9778831040859224, 1.0985574696608611], Fake: [-0.38926272854208949, 0.30557722775850882]) \n",
      "1000: D: 0.04351293295621872/0.015439733862876892 G: 3.9179484844207764 (Real: [3.9195833837985994, 1.1447051885462327], Fake: [1.303229666352272, 0.50094379356635221]) \n",
      "1200: D: 0.12069693207740784/0.19963468611240387 G: 2.3182003498077393 (Real: [4.237438430786133, 1.3047203523687139], Fake: [3.0635278207063674, 0.92486335954027987]) \n",
      "1400: D: 0.5045600533485413/1.7040975093841553 G: 0.9030115008354187 (Real: [4.0019299948215483, 1.1755488251517452], Fake: [4.4875133657455448, 1.1334169562582783]) \n",
      "1600: D: 0.4277249574661255/2.6394684314727783 G: 0.15130460262298584 (Real: [4.0466081130504605, 1.287681683839458], Fake: [5.0340542900562291, 1.274868321182538]) \n",
      "1800: D: 1.1153473854064941/0.7860763072967529 G: 0.8231314420700073 (Real: [4.0109371840953827, 1.2594012418047282], Fake: [5.0874817228317264, 1.4870602581626682]) \n",
      "2000: D: 1.1496968269348145/0.5963533520698547 G: 1.0670220851898193 (Real: [4.0469627487659459, 1.2885280211843755], Fake: [5.3747441601753234, 1.2488444768747924]) \n",
      "2200: D: 0.6510056853294373/0.2038157880306244 G: 1.3873594999313354 (Real: [4.3240076577663418, 1.2662435677230304], Fake: [4.6945802450180052, 1.5127341252894162]) \n",
      "2400: D: 0.5361521244049072/0.4671763479709625 G: 0.7792191505432129 (Real: [3.9434133267402647, 1.3143775310193837], Fake: [4.6203063523769377, 1.19899407099719]) \n",
      "2600: D: 1.0033175945281982/0.6609319448471069 G: 0.5614461302757263 (Real: [4.1533424067497258, 1.2927640752471927], Fake: [3.5867731553316116, 1.3984474301559482]) \n",
      "2800: D: 0.7005774974822998/0.8039321303367615 G: 0.476898193359375 (Real: [3.9614194822311402, 1.2506901012337353], Fake: [3.5953917443752288, 1.0935949449217914]) \n",
      "3000: D: 0.5922554731369019/0.4593636095523834 G: 0.5590038299560547 (Real: [3.9789889478683471, 1.2165736086652703], Fake: [3.0389899277687071, 1.2686100695461713]) \n",
      "3200: D: 0.6083734035491943/0.6439991593360901 G: 0.44431430101394653 (Real: [3.9304573196172714, 1.2930616627796596], Fake: [3.8072469025850295, 1.2774304408308192]) \n",
      "3400: D: 0.8342233300209045/0.7011584639549255 G: 1.055466890335083 (Real: [3.8555041575431823, 1.1659886973497566], Fake: [4.5221952700614931, 1.2326589291986261]) \n",
      "3600: D: 0.5422624945640564/0.4161447584629059 G: 1.2002532482147217 (Real: [4.1711639320850376, 1.2924800326629471], Fake: [4.5524045920372007, 1.3273845004941991]) \n",
      "3800: D: 0.8233522176742554/0.7710584998130798 G: 0.9349318742752075 (Real: [4.0127243260294199, 1.2340234116604281], Fake: [4.3682400393486027, 1.2278164770846007]) \n",
      "4000: D: 0.9152852296829224/1.0084160566329956 G: 0.4951581060886383 (Real: [4.1120876884460449, 1.2713512878410904], Fake: [3.6810205686092377, 1.2580001671016623]) \n",
      "4200: D: 0.6641653776168823/0.8141865730285645 G: 0.8805789351463318 (Real: [3.9503351593017579, 1.1259055837039367], Fake: [3.5337620532512664, 1.1908678600785845]) \n",
      "4400: D: 0.6493794918060303/0.5988080501556396 G: 0.7040019035339355 (Real: [3.9418321990966798, 1.1781196227005126], Fake: [3.4197925484180449, 1.4645360776193803]) \n",
      "4600: D: 0.6753860712051392/0.6910781860351562 G: 0.5036612153053284 (Real: [4.097597661018372, 1.3091853124868686], Fake: [4.1190530145168305, 1.4570837637817615]) \n",
      "4800: D: 0.9194965362548828/0.7295243144035339 G: 0.2000853717327118 (Real: [4.1634069538116458, 1.1553705438556698], Fake: [4.3610216891765594, 1.3732117472902261]) \n",
      "5000: D: 0.7019204497337341/0.5097169876098633 G: 0.5269955992698669 (Real: [3.9577450436353683, 1.2076245895810824], Fake: [3.7612904798984528, 1.2318123876104363]) \n",
      "5200: D: 0.5752590298652649/0.5747267603874207 G: 0.8290275931358337 (Real: [4.04950684428215, 1.2055739555293699], Fake: [3.5861490559577942, 1.175601655956547]) \n",
      "5400: D: 0.6836038827896118/0.7102792263031006 G: 0.5000492930412292 (Real: [3.9354038554430009, 1.277195449381354], Fake: [3.958464125394821, 1.2772124347243532]) \n",
      "5600: D: 0.5942557454109192/0.3715594410896301 G: 0.6049378514289856 (Real: [3.9288671368360522, 1.3273113902013611], Fake: [4.0029064261913296, 1.5134389862935851]) \n",
      "5800: D: 0.7757550477981567/0.6192744970321655 G: 0.7936191558837891 (Real: [3.9171336263418199, 1.2186744022672944], Fake: [3.8176265907287599, 1.3736057287338452]) \n",
      "6000: D: 0.7555994987487793/0.7027100920677185 G: 0.3470219671726227 (Real: [4.0576095962524414, 1.3993890793873547], Fake: [3.4270774012804033, 1.4182086053810832]) \n",
      "6200: D: 0.5705273747444153/0.5446593761444092 G: 0.7296960353851318 (Real: [3.9555246740579606, 1.2765392050728459], Fake: [3.773398088812828, 1.315056741640243]) \n",
      "6400: D: 0.9488032460212708/0.48493996262550354 G: 0.6492303013801575 (Real: [3.9107225394248961, 1.1622076999568052], Fake: [4.1833454847335814, 1.3111456883239387]) \n",
      "6600: D: 0.8048421740531921/0.5915120840072632 G: 0.767508864402771 (Real: [3.9178635883331299, 1.2622282908180189], Fake: [3.8910732507705688, 1.1772928373858804]) \n",
      "6800: D: 0.48284533619880676/0.591081440448761 G: 0.7176924347877502 (Real: [4.022793068289757, 1.2051309610971637], Fake: [4.0382393455505374, 1.2146790606290636]) \n",
      "7000: D: 0.49836990237236023/0.5143936276435852 G: 0.7713378667831421 (Real: [4.0896017038822174, 1.2638970431073908], Fake: [4.2499440312385559, 1.1910505342818991]) \n",
      "7200: D: 0.6050724387168884/0.6051875948905945 G: 0.5548508167266846 (Real: [4.0444656538963315, 1.199142120317078], Fake: [4.0501512765884398, 0.94845957734423836]) \n",
      "7400: D: 0.9342707395553589/0.5303415060043335 G: 0.8626270890235901 (Real: [3.9395809158030897, 1.3214552357668414], Fake: [3.9870003902912141, 1.1303830279852733]) \n",
      "7600: D: 0.8922737836837769/0.4487067461013794 G: 1.0255964994430542 (Real: [3.8006328415870665, 1.1692749755146459], Fake: [4.3327014231681824, 1.1578927176842635]) \n",
      "7800: D: 0.7111162543296814/0.6000383496284485 G: 0.8511224389076233 (Real: [4.0048900416493414, 1.3316604596746069], Fake: [3.8363810223340988, 1.3443173778292929]) \n",
      "8000: D: 0.7751331925392151/0.5166328549385071 G: 0.7537255883216858 (Real: [4.0619306936860085, 1.3533720790582873], Fake: [3.6706799280643465, 1.3574851394448717]) \n",
      "8200: D: 0.7370643019676208/0.6676291227340698 G: 1.2305415868759155 (Real: [4.0269763708114628, 1.3368961263362897], Fake: [4.1845889639854432, 1.2324999168667137]) \n",
      "8400: D: 0.7694270610809326/0.5161903500556946 G: 0.5766803622245789 (Real: [3.9829773235321047, 1.0331647431868141], Fake: [3.4537583187222483, 1.3778163231147842]) \n",
      "8600: D: 0.6588660478591919/0.5153627395629883 G: 0.5403382182121277 (Real: [3.8630137503147126, 1.2023179204996297], Fake: [4.2639098018407822, 1.1472186162564326]) \n",
      "8800: D: 0.3686271905899048/0.6498180031776428 G: 0.96332848072052 (Real: [4.1611719733476642, 1.2672452458422567], Fake: [3.8868674981594085, 1.2472265071141233]) \n",
      "9000: D: 0.5924137234687805/0.6092716455459595 G: 0.9333160519599915 (Real: [3.9027585268020628, 1.1477995029037056], Fake: [4.3776250380277633, 1.1053400274744882]) \n",
      "9200: D: 0.5552944540977478/0.7323428988456726 G: 1.4327081441879272 (Real: [3.8029143712669611, 1.2759499451099565], Fake: [4.1378799873590468, 1.0944641928869949]) \n",
      "9400: D: 0.588939905166626/0.6656511425971985 G: 1.0958194732666016 (Real: [4.1612578788399697, 1.2682329550194533], Fake: [4.1665571844577789, 1.2207713082844429]) \n",
      "9600: D: 0.6534979939460754/1.0715510845184326 G: 0.4455718398094177 (Real: [4.0741379284858708, 1.272820880323033], Fake: [4.1865740847587585, 1.1495456574777256]) \n",
      "9800: D: 0.5888434052467346/0.4215708374977112 G: 0.9982914328575134 (Real: [4.0167838287353517, 1.1761690645024307], Fake: [4.2406689274311065, 1.2834581159888798]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000: D: 0.5729203224182129/0.49057695269584656 G: 1.0445129871368408 (Real: [4.145910779237747, 1.3416634060166293], Fake: [4.1204122048616405, 1.1044755617378577]) \n",
      "10200: D: 1.1420321464538574/0.7699006795883179 G: 0.7112780809402466 (Real: [4.0053596019744875, 1.1305459219223297], Fake: [3.9794211101531984, 1.3490466391922549]) \n",
      "10400: D: 0.7340941429138184/0.2624286115169525 G: 1.2078440189361572 (Real: [3.8517177972197532, 1.4292914224937217], Fake: [4.0255674493312839, 1.3381280381062433]) \n",
      "10600: D: 0.4878266155719757/0.4451640248298645 G: 0.9934609532356262 (Real: [4.1101989614963532, 1.3230360417616684], Fake: [4.0249018996953962, 1.2920780006085295]) \n",
      "10800: D: 0.8899770975112915/0.5163384675979614 G: 1.0826796293258667 (Real: [3.9148611101508139, 1.2682766245917632], Fake: [3.9188432061672209, 1.2643077708311175]) \n",
      "11000: D: 0.5683136582374573/0.6140703558921814 G: 0.9674574136734009 (Real: [4.0380168223381041, 1.1813273217305131], Fake: [4.0974157047271724, 1.1693897938496034]) \n",
      "11200: D: 0.7658736705780029/0.7726669311523438 G: 0.48481228947639465 (Real: [3.8901093053817748, 1.0214691946222691], Fake: [4.0959119200706482, 1.2182124023000223]) \n",
      "11400: D: 1.0257192850112915/0.6362074613571167 G: 0.9559054374694824 (Real: [3.9728773987293242, 1.3563797781367093], Fake: [4.17067268550396, 1.1935435843358118]) \n",
      "11600: D: 0.7241341471672058/0.4267219603061676 G: 0.4005946218967438 (Real: [4.2483335471153261, 1.2709540580716168], Fake: [4.1563065659999845, 1.1251823326739492]) \n",
      "11800: D: 0.3505612313747406/0.8821629285812378 G: 1.123589277267456 (Real: [3.8839006757736207, 1.3536382454683822], Fake: [3.8199840760231019, 1.3311504072511176]) \n",
      "12000: D: 1.2396866083145142/0.3860279619693756 G: 1.0760921239852905 (Real: [4.0950588536262513, 0.99371015223581516], Fake: [3.9369610935449599, 1.2807893591805717]) \n",
      "12200: D: 0.8703049421310425/0.39764606952667236 G: 1.0271528959274292 (Real: [4.0555188333988186, 1.327486417666814], Fake: [4.3286527729034425, 1.0779279152736052]) \n",
      "12400: D: 0.31730467081069946/0.3143778443336487 G: 1.1115001440048218 (Real: [4.1887642483413217, 1.3012881443614055], Fake: [3.8347925221920014, 1.1498474246806181]) \n",
      "12600: D: 1.0494440793991089/0.4643542170524597 G: 1.3471561670303345 (Real: [4.0451595091819765, 1.1062150379371596], Fake: [4.0435394680500032, 1.4101949104892941]) \n",
      "12800: D: 0.18694062530994415/0.6418215036392212 G: 1.4294675588607788 (Real: [3.9426253652572631, 1.2446707578638505], Fake: [4.3250297403335569, 1.2073798613715414]) \n",
      "13000: D: 0.9768908023834229/0.6908297538757324 G: 0.9714341163635254 (Real: [3.9574362218379973, 1.1432987892360951], Fake: [3.9786110097169876, 1.2322948567324665]) \n",
      "13200: D: 0.41030141711235046/0.4980549216270447 G: 1.157915472984314 (Real: [4.1291678714752198, 1.131071427783594], Fake: [3.8051736557483675, 1.2313150668059307]) \n",
      "13400: D: 0.2209414839744568/0.8057713508605957 G: 1.2601420879364014 (Real: [4.1096060520410536, 1.2452955153868697], Fake: [4.0959963971376423, 1.1996549701892796]) \n",
      "13600: D: 0.07599734514951706/0.23115186393260956 G: 0.5807958245277405 (Real: [3.8581732457876203, 1.1834603145159108], Fake: [3.7976638209819793, 1.241025286747355]) \n",
      "13800: D: 1.101142406463623/0.30105462670326233 G: 0.7141393423080444 (Real: [4.2931334269046779, 1.2094512603845569], Fake: [4.0578479969501497, 1.3363757062164134]) \n",
      "14000: D: 0.7158458828926086/0.33784493803977966 G: 0.6858717799186707 (Real: [3.7688060212135315, 1.2083778778273873], Fake: [4.0119440054893492, 1.218100243165452]) \n",
      "14200: D: 0.4928753077983856/0.5782139301300049 G: 0.8124106526374817 (Real: [4.0323457098007198, 1.2256721375251953], Fake: [3.9574051368236542, 1.2229839026734173]) \n",
      "14400: D: 0.27995070815086365/0.40899285674095154 G: 0.8428452610969543 (Real: [3.9091096782684325, 1.3713459820836227], Fake: [3.9527071917057039, 1.2413984842788572]) \n",
      "14600: D: 0.9110604524612427/0.7463461756706238 G: 0.8074053525924683 (Real: [4.0382295981049534, 1.1735317423395846], Fake: [4.0884305155277252, 1.1632704940233602]) \n",
      "14800: D: 0.2606829106807709/0.9640840291976929 G: 2.060908079147339 (Real: [4.1741303527355198, 1.2939889962059423], Fake: [3.9678732919692994, 1.2596428714473291]) \n",
      "15000: D: 1.4465007781982422/0.6078513264656067 G: 0.3082796037197113 (Real: [4.1948302507400514, 1.1596175803795488], Fake: [4.1443997871875764, 1.3182592698784144]) \n",
      "15200: D: 0.29967647790908813/0.517862856388092 G: 2.0530242919921875 (Real: [4.1619071912765504, 1.1803880133107585], Fake: [4.2803118884563442, 1.0548725999131192]) \n",
      "15400: D: 0.19186434149742126/0.1955745816230774 G: 1.7981985807418823 (Real: [4.027448907494545, 1.1851036385667837], Fake: [4.0635774707794186, 1.1739422022514741]) \n",
      "15600: D: 0.07569718360900879/0.6928300261497498 G: 1.5797834396362305 (Real: [4.0004906892776493, 1.3053175312542051], Fake: [3.8237460696697236, 1.1050105160252468]) \n",
      "15800: D: 0.5046278834342957/0.6968052387237549 G: 0.8754388093948364 (Real: [3.8758596312999725, 1.2272323186270251], Fake: [3.9521952700614928, 1.2255991291144304]) \n",
      "16000: D: 1.8680282831192017/0.2203167974948883 G: 1.5285444259643555 (Real: [3.9855760598182677, 1.1308412313476315], Fake: [4.2773690581321713, 1.0643575657214519]) \n",
      "16200: D: 0.005258174147456884/0.2367042899131775 G: 1.5488953590393066 (Real: [4.1083374989032748, 1.2254143157829678], Fake: [4.0089853775501254, 1.2805405755107981]) \n",
      "16400: D: 0.17825433611869812/0.1817896068096161 G: 1.2011593580245972 (Real: [3.9897955918312071, 1.139123434066809], Fake: [4.1792339122295381, 1.0870926093295339]) \n",
      "16600: D: 0.8887361884117126/0.2718765139579773 G: 0.6644613146781921 (Real: [3.8714527481794359, 1.2084798692877878], Fake: [3.8277800035476686, 1.3123081534554617]) \n",
      "16800: D: 0.04580668732523918/0.330718070268631 G: 0.6022501587867737 (Real: [4.2016943597793581, 1.2617248086242965], Fake: [4.1190334045886994, 1.2344609812679326]) \n",
      "17000: D: 1.133486270904541/0.16458667814731598 G: 2.1326236724853516 (Real: [4.0568430653214458, 1.2644305353767515], Fake: [3.9432007265090943, 1.4570414539103664]) \n",
      "17200: D: 0.004906152840703726/0.1595521718263626 G: 0.5319394469261169 (Real: [3.8878433924913405, 1.3293429960650121], Fake: [4.1175734519958498, 1.4771056260023026]) \n",
      "17400: D: 0.1403229683637619/0.24945276975631714 G: 2.257779598236084 (Real: [4.0118841135501864, 1.2648478529655764], Fake: [4.1501274967193602, 1.2038822174602366]) \n",
      "17600: D: 0.0037557589821517467/0.14483308792114258 G: 1.161637544631958 (Real: [4.0202174431085584, 1.1651723841560413], Fake: [3.7801397955417633, 1.0973661138133255]) \n",
      "17800: D: 1.2973217964172363/1.5345778465270996 G: 0.6027330756187439 (Real: [4.1020967805385586, 1.392731341785364], Fake: [4.4841321980953213, 1.0317253592159836]) \n",
      "18000: D: 0.26000624895095825/0.45471933484077454 G: 0.6538819074630737 (Real: [3.801813418865204, 1.3065448300730824], Fake: [4.0483634239435196, 1.2550313856524917]) \n",
      "18200: D: 1.3075666427612305/0.7766324877738953 G: 1.9694918394088745 (Real: [4.010889368057251, 1.1279979621618845], Fake: [3.8938156354427336, 1.3385591481052268]) \n",
      "18400: D: 0.3582564890384674/1.220463752746582 G: 0.6265998482704163 (Real: [3.8717956995964049, 1.1882231048010765], Fake: [4.155058391094208, 1.1682695767163176]) \n",
      "18600: D: 1.3444627523422241/0.48690277338027954 G: 1.5043878555297852 (Real: [4.192111921310425, 1.1946109871964763], Fake: [4.0841469007730486, 1.1169148852000483]) \n",
      "18800: D: 0.019620252773165703/0.8528329133987427 G: 0.5019357204437256 (Real: [3.9986970186233521, 1.186842124214555], Fake: [4.0288590478897097, 1.2308359047802264]) \n",
      "19000: D: 1.1774382591247559/1.0737764835357666 G: 1.7738021612167358 (Real: [3.8392264145612716, 1.3018707901360858], Fake: [3.9605778056383132, 1.3956911477399516]) \n",
      "19200: D: 0.8655301332473755/0.5422149300575256 G: 1.166843295097351 (Real: [3.9102861368656159, 1.2554544934778695], Fake: [4.0326903951168056, 1.2748604425413765]) \n",
      "19400: D: 0.3381238877773285/0.5144506692886353 G: 0.5212013721466064 (Real: [4.0934059953689577, 1.2997533025948012], Fake: [4.2512062060832978, 1.236610613574511]) \n",
      "19600: D: 0.29578256607055664/2.003713607788086 G: 1.259299874305725 (Real: [3.9934445720911027, 1.2969344416049087], Fake: [4.4090895378589634, 1.281623204735685]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19800: D: 0.19312016665935516/0.4549640715122223 G: 1.6338828802108765 (Real: [4.0336783683300022, 1.0857848212896839], Fake: [3.9983774733543398, 1.1859897767005405]) \n",
      "20000: D: 0.33223336935043335/0.24320967495441437 G: 1.179128885269165 (Real: [3.9047317101061343, 1.2826183678407914], Fake: [4.0308008933067319, 1.0580101947826166]) \n",
      "20200: D: 0.2904634475708008/0.9970558285713196 G: 1.829633116722107 (Real: [3.9558619594573976, 1.2575629152182586], Fake: [4.111473888754845, 1.188649399466666]) \n",
      "20400: D: 0.2684444189071655/0.5881476402282715 G: 1.1585514545440674 (Real: [4.0228100979328154, 1.1084062458011388], Fake: [4.3453722763061524, 1.2790166034832122]) \n",
      "20600: D: 0.12829643487930298/0.7798513770103455 G: 0.41847172379493713 (Real: [3.9155438077449798, 1.3614451838848478], Fake: [4.4139680230617522, 1.3405579231725515]) \n",
      "20800: D: 0.07240618020296097/0.5143404603004456 G: 0.07385839521884918 (Real: [3.7377527683973311, 1.2162414621025703], Fake: [4.175955717563629, 1.1753697089770321]) \n",
      "21000: D: 0.08048169314861298/1.3486188650131226 G: 1.8279274702072144 (Real: [4.1550741672515867, 1.1791978156082479], Fake: [4.1691359382867814, 1.3588016265157119]) \n",
      "21200: D: 0.20780406892299652/0.5527442097663879 G: 0.8753769993782043 (Real: [3.9449345725774765, 1.2439118432192149], Fake: [4.4403820031881329, 1.2979157132024997]) \n",
      "21400: D: 0.2073894590139389/1.334183692932129 G: 0.5979591012001038 (Real: [3.9042301654815672, 1.2380738881111177], Fake: [4.1271753185987476, 1.1536148940063877]) \n",
      "21600: D: 0.16508230566978455/0.13162100315093994 G: 0.9258453845977783 (Real: [4.1239816212654112, 1.2905319855041912], Fake: [3.9914460766315458, 1.3966789082358624]) \n",
      "21800: D: 0.051236025989055634/0.05741853266954422 G: 0.4930112361907959 (Real: [3.792574157714844, 1.189053584322775], Fake: [4.3222581699490545, 1.3754746365345165]) \n",
      "22000: D: 0.048970483243465424/0.38651242852211 G: 2.1192638874053955 (Real: [3.8728485465049745, 1.2668888499168145], Fake: [4.4998888921737672, 1.4120456290631149]) \n",
      "22200: D: 0.2628198266029358/0.07815492153167725 G: 1.9622315168380737 (Real: [3.9282520681619646, 1.2457333882807882], Fake: [4.3872639000415798, 1.1025456985489643]) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-768385343e03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0md_real_decision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_real_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0md_real_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_real_decision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# ones = true\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0md_real_error\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# compute/store gradients, but don't change params\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m#  1B: Train D on fake\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \"\"\"\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m---> 98\u001b[1;33m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generative Adversarial Networks (GAN) example in PyTorch.\n",
    "# See related blog post at https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1    # size of generated output vector\n",
    "d_input_size = 100   # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 30000\n",
    "print_interval = 200\n",
    "d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
    "g_steps = 1\n",
    "\n",
    "# ### Uncomment only one of these\n",
    "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "\n",
    "print(\"Using data [%s]\" % (name))\n",
    "\n",
    "# ##### DATA: Target data and generator input data\n",
    "\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian\n",
    "\n",
    "# ##### MODELS: Generator model and discriminator model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))\n",
    "\n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    return torch.cat([data, diffs], 1)\n",
    "\n",
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        d_real_data = Variable(d_sampler(d_input_size))\n",
    "        d_real_decision = D(preprocess(d_real_data))\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: D: %s/%s G: %s (Real: %s, Fake: %s) \" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
